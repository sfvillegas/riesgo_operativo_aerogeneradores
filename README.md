![image](https://github.com/user-attachments/assets/dd536d74-e3e5-455c-9d58-a9f3d8ea0a04)
![image](https://github.com/user-attachments/assets/fdea40a9-da50-4c1f-851f-7a2c18e3ad1f)


# PredicciÃ³n del Riesgo Operativo de Aerogeneradores en Condiciones ClimÃ¡ticas Extremas en Tierra del Fuego

## ğŸ“š DescripciÃ³n General

Este proyecto tiene como objetivo desarrollar un modelo de clasificaciÃ³n multiclase que prediga el **nivel de riesgo operativo** (bajo, medio, alto) de los aerogeneradores del Parque EÃ³lico RÃ­o Cullen, ubicado en Tierra del Fuego, Argentina. Se basa en datos operativos de las turbinas y datos meteorolÃ³gicos histÃ³ricos de la zona.

El enfoque estÃ¡ orientado a mejorar el mantenimiento preventivo y la eficiencia operativa, anticipando condiciones climÃ¡ticas adversas que puedan afectar el rendimiento y seguridad de los aerogeneradores.

## ğŸ—‚ï¸ Estructura del Proyecto

- `data/raw/`:
  - Datos originales sin procesar.
  - **T1.csv**: Datos operativos de aerogeneradores (SCADA).
  - **export.csv**: Datos meteorolÃ³gicos histÃ³ricos de RÃ­o Grande.
  
- `data/processed/`:
  - Datos limpios y transformados listos para el modelado.
  - **dataset_final_limpio.csv**.

- `notebooks/`:
  - Notebooks de exploraciÃ³n, limpieza de datos, entrenamiento de modelos y evaluaciÃ³n.
  - **modelo_aerogeneradores.ipynb**

- `src/`:
  - CÃ³digo fuente del proyecto (scripts para preprocesamiento y modelado).
  
- `models/`:
  - Modelos entrenados y serializados (`.pkl`, `.joblib`).

- `reports/`:
  - Visualizaciones, resultados de anÃ¡lisis y mÃ©tricas del modelo.

- `docs/`:
  - DocumentaciÃ³n adicional y PDFs del proyecto.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- Python 3.11
- Pandas
- NumPy
- Scikit-learn
- Matplotlib / Seaborn
- Jupyter Notebook

## ğŸ“ˆ Proceso de Trabajo (Planificado)

1. **AdquisiciÃ³n de Datos**:
   - RecopilaciÃ³n de datos SCADA de aerogeneradores.
   - ObtenciÃ³n de datos meteorolÃ³gicos histÃ³ricos de Meteostat.

2. **Preprocesamiento**:
   - Limpieza de datos: eliminaciÃ³n de valores nulos y duplicados.
   - ConversiÃ³n de formatos de fecha/hora y unificaciÃ³n de ambos datasets.

3. **AnÃ¡lisis Exploratorio de Datos (EDA)** (Pendiente de realizar):
   - AnÃ¡lisis de la distribuciÃ³n de variables mediante histogramas y boxplots.
   - AnÃ¡lisis de correlaciones y relaciones bivariadas entre variables operativas y climÃ¡ticas.
   - AnÃ¡lisis de series temporales para identificar tendencias y estacionalidades.
   - Tratamiento de valores atÃ­picos y selecciÃ³n de variables relevantes.
   
4. **IngenierÃ­a de CaracterÃ­sticas**:
   - GeneraciÃ³n de nuevas variables relevantes para la predicciÃ³n.
   - NormalizaciÃ³n y escalado si es necesario.

5. **Modelado**:
   - AplicaciÃ³n de modelos de clasificaciÃ³n supervisada: Ãrboles de DecisiÃ³n, Random Forest, etc.
   - Ajuste de hiperparÃ¡metros mediante tÃ©cnicas como Grid Search.

6. **EvaluaciÃ³n**:
   - EvaluaciÃ³n del desempeÃ±o del modelo utilizando mÃ©tricas como PrecisiÃ³n, Recall, F1-Score y Matriz de ConfusiÃ³n.
   - InterpretaciÃ³n de la importancia de caracterÃ­sticas.

7. **Conclusiones**:
   - InterpretaciÃ³n de los resultados.
   - Recomendaciones para optimizar la gestiÃ³n del riesgo operativo.

## ğŸ“„ Origen de los Datos

- **SCADA**: Datos histÃ³ricos de sensores SCADA de aerogeneradores, sobre producciÃ³n y variables operativas de aerogeneradores. [Ver PÃ¡gina de Referencia (Kaggle Dataset)](https://www.kaggle.com/datasets/berkerisen/wind-turbine-scada-dataset)

- **Meteostat**: Datos meteorolÃ³gicos histÃ³ricos de RÃ­o Grande, Tierra del Fuego. [Ver Meteostat](https://meteostat.net/es/place/ar/rio-grande?s=87934&t=2018-01-01/2018-12-18)

  
## ğŸš€ Estado del Proyecto

> **En Desarrollo**: Actualmente en fase de limpieza de datos, pendiente de iniciar el anÃ¡lisis exploratorio de datos (EDA).
>
## ğŸ“‚ Acceso a los Datos Originales

Los datasets utilizados en este proyecto estÃ¡n disponibles en:

- Carpeta: `data/raw/`
  - `T1.csv`: Dataset SCADA de aerogeneradores.
  - `export.csv`: Dataset meteorolÃ³gico histÃ³rico.

> âš ï¸ **Nota importante:** Debido al tamaÃ±o de los archivos no se pueden visualizar directamente pero estÃ¡n correctamente almacenados en el repositorio y disponibles para su descarga.

---
Project Organization

Project Organization
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile <- Makefile with commands like make data or make train
â”œâ”€â”€ README.md <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚ â”œâ”€â”€ external <- Data from third party sources.
â”‚ â”œâ”€â”€ interim <- Intermediate data that has been transformed.
â”‚ â”œâ”€â”€ processed <- The final, canonical data sets for modeling.
â”‚ â””â”€â”€ raw <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs <- A default Sphinx project; see sphinx-doc.org for details
â”‚
â”œâ”€â”€ models <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚ the creator's initials, and a short - delimited description, e.g.
â”‚ 1.0-jqp-initial-data-exploration.
â”‚
â”œâ”€â”€ references <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚ â””â”€â”€ figures <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt <- The requirements file for reproducing the analysis environment, e.g.
â”‚ generated with pip freeze > requirements.txt
â”‚
â”œâ”€â”€ setup.py <- makes project pip installable (pip install -e .) so src can be imported
â”œâ”€â”€ src <- Source code for use in this project.
â”‚ â”œâ”€â”€ init.py <- Makes src a Python module
â”‚ â”‚
â”‚ â”œâ”€â”€ data <- Scripts to download or generate data
â”‚ â”‚ â””â”€â”€ make_dataset.py
â”‚ â”‚
â”‚ â”œâ”€â”€ features <- Scripts to turn raw data into features for modeling
â”‚ â”‚ â””â”€â”€ build_features.py
â”‚ â”‚
â”‚ â”œâ”€â”€ models <- Scripts to train models and then use trained models to make
â”‚ â”‚ â”‚ predictions
â”‚ â”‚ â”œâ”€â”€ predict_model.py
â”‚ â”‚ â””â”€â”€ train_model.py
â”‚ â”‚
â”‚ â””â”€â”€ visualization <- Scripts to create exploratory and results oriented visualizations
â”‚ â””â”€â”€ visualize.py
â”‚
â””â”€â”€ tox.ini <- tox file with settings for running tox; see tox.readthedocs.io

